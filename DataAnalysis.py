from operator import attrgetter

import pandas as pd
import pydriller as py
from statistics import *
import csv
from datetime import datetime
import numpy as np
from getReleases import getReleases
import logging
import threading
import random
from multiprocessing import Process,Pool


logger = logging.getLogger('data_analysis_logger')
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler('log.txt',mode='w')
fh.setLevel(logging.DEBUG)
logger.addHandler(fh)

df = pd.read_csv('RepositoryeCommit.csv', sep='|',
                 names=['CVE', 'summary', 'CWE', 'Published date', 'Last update', 'CVSS', 'Impact confidentiality',
                        'Impact integrity', 'Impact availability', 'Product name', 'Vendor name', 'Url_repository',
                        'Commit_id', 'Url_trackers'], skiprows=1)
dict = dict()


def introducingCommitFile(repo, commit, v):
    # logger.info(repo)
    # logger.info(commit)
    # logger.info(v)
    logger.info("Metodo introducing commit file")
    repo._to_commit=commit
    commits = repo.traverse_commits()
    # logger.info(len(list(commits)))
    for commit in commits:

        for m in commit.modifications:
            if m.filename == v.filename:
                logger.info("trovato commit")

                return commit


def when(introducingCommit, modifications, repo):
    numCommit = {}
    # dict[(row['CVE'],row['Product name'])]=commits
    # dict[(cve, product,repo)] = commits
    oldestCommit = min(introducingCommit, key=attrgetter('author_date'))

    logger.info("Oldest commit"+oldestCommit.hash)

    for k, v in modifications.items():
        if k == oldestCommit.hash:
            for m in v:
                if (m.old_path != None):
                    ic = introducingCommitFile(repo, oldestCommit.hash, m)
                    logger.info("Commit trovato "+ic.hash)
                    if (ic != None):
                        commit = py.RepositoryMining(repo, from_commit=ic.hash,
                                                     to_commit=oldestCommit.hash).traverse_commits()
                        numCommit[m.filename] = len(list(commit))

    return numCommit


def introducing_commit(repo, commitHash):
    modifications = {}
    introducingCommit = []

    logger.info(commitHash)
    for commit in repo.traverse_commits():
        gr = py.GitRepository(commit.project_path)
        if commit.hash == commitHash:
            introducing_commit = gr.get_commits_last_modified_lines(commit)
            logger.info("Introducing commit "+ str(len(introducing_commit)))
            for commit in introducing_commit:
                repo._single=commit
                #rp = py.RepositoryMining(repo, single=commit)

                commitObjects = repo.traverse_commits()

                for commitObject in commitObjects:

                    modifications[commitObject.hash] = commitObject.modifications

                    introducingCommit.append(commitObject)

    return (introducingCommit, modifications)


def isEnhancement(commit):
    # for commit in py.RepositoryMining(repo,single=commit).traverse_commits():
    # logger.info(commit.msg)
    if (
            'updat' or 'modif' or 'upgrad' or 'export' or 'remov' or 'integrat' or 'support' or 'enhancement' or 'replace' or 'includ' or 'expos' or 'better' or 'svn' or 'generate') in commit.msg.lower():
        return True
    else:
        return False


def isNewFeature(commit):
    # for commit in py.RepositoryMining(repo,single=commit).traverse_commits():
    if ('new' or 'feature' or 'add' or 'create' or 'introduc' or 'migrat') in commit.msg.lower():
        return True
    else:
        return False


def isBugFixing(commit):
    # for commit in py.RepositoryMining(repo,single=commit).traverse_commits():
    if (
            'fix' or 'repair' or 'error' or 'avoid' or 'can ' or 'bug ' or 'issue ' or '#' or 'exception') in commit.msg.lower():
        return True
    else:
        return False


def isRefactoring(commit):
    # for commit in py.RepositoryMining(repo,single=commit).traverse_commits():
    if (
            'renam' or 'reorganiz' or 'refactor' or 'clean' or 'polish' or 'typo' or 'move' or 'extract' or 'reorder' or 're-order') in commit.msg.lower():
        return True
    else:
        return False


def why(row, repo, introducingCommit):

    release = getReleases(repo._path_to_repo[0])
    releases = release.getMajorReleases()

    countBF = 0
    countE = 0
    countNF = 0
    countR = 0
    countWR_OD = 0
    countWR_OW = 0
    countWR_OM = 0
    countWR_M = 0
    countPS_OW = 0
    countPS_OM = 0
    countPS_OY = 0
    countPS_M = 0
    countW_H = 0
    countW_M = 0
    countW_L = 0
    countPT_E = 0
    countPT_NC = 0
    countPT_M = 0
    tags = []
    for commit in introducingCommit:

        if (isBugFixing(commit)):
            countBF = countBF + 1
        if (isEnhancement(commit)):
            countE = countE + 1
        if (isNewFeature(commit)):
            countNF = countNF + 1
        if (isRefactoring(commit)):
            countR = countR + 1
        ps = projectStartupTag(repo, commit)
        logger.info("Project startup " + ps)
        wl = workloadTag(repo, commit)
        repo._since=None
        repo._to=None
        logger.info("Workload " + wl)
        if wl == "H":
            countW_H = countW_H + 1
        if wl == "M":
            countW_M = countW_M + 1
        if wl == "L":
            countW_L = countW_L + 1
        if ps == "OW":
            countPS_OW = countPS_OW + 1
        if ps == "OM":
            countPS_OM = countPS_OM + 1
        if ps == "OY":
            countPS_OY = countPS_OY + 1
        if ps == "M":
            countPS_M = countPS_M + 1
        pt = projectTenureTag(repo, commit)
        if pt == "E":
            countPT_E = countPT_E + 1
        if pt == "M":
            countPT_M = countPT_M + 1
        if pt == "NC":
            countPT_NC = countPT_NC + 1
        logger.info("Project tenure " + pt)

        wr = workingOnRelease(commit, releases)
        logger.info("Working on Release " + wr)
        if wr == "OD":
            countWR_OD = countWR_OD + 1
        if wr == "OW":
            countWR_OW = countWR_OW + 1
        if wr == "OM":
            countWR_OM = countWR_OM + 1
        if wr == "M":
            countWR_M = countWR_M + 1

    tags.append(countBF)
    tags.append(countE)
    tags.append(countNF)
    tags.append(countR)
    tags.append(countWR_OD)
    tags.append(countWR_OW)
    tags.append(countWR_OM)
    tags.append(countWR_M)
    tags.append(countPS_OW)
    tags.append(countPS_OM)
    tags.append(countPS_OY)
    tags.append(countPS_M)
    tags.append(countW_H)
    tags.append(countW_M)
    tags.append(countW_L)
    tags.append(countPT_E)
    tags.append(countPT_M)
    tags.append(countPT_NC)

    whyFile = open("Risultati/risWhy.csv", "a", newline='')
    writerWhy = csv.writer(whyFile, delimiter="|")

    writerWhy.writerow(
        [row[0], row[9], tags[0], tags[1], tags[2], tags[3], tags[4], tags[5], tags[6], tags[7], tags[8], tags[9],
         tags[10], tags[11], tags[12], tags[13], tags[14], tags[15], tags[16], tags[17]])
    logger.info(row[0] + "|" + row[9] + "|" + str(tags[0]) + "|" + str(tags[1]) + "|" + str(tags[2]) + "|" + str(
        tags[3]) + "|" + str(tags[4]) + "|" + str(tags[5]) + "|" + str(tags[6]) + "|" + str(tags[7]) + "|" + str(
        tags[8]) + "|" + str(tags[9]) + "|" + str(tags[10]) + "|" + str(tags[11]) + "|" + str(tags[12]) + "|" + str(
        tags[13]) + "|" + str(tags[14]) + "|" + str(tags[15]) + "|" + str(tags[16]) + "|" + str(tags[17]))
    whyFile.close()


def projectStartupTag(repo, commit):
    allCommit = repo.traverse_commits()
    firstCommit = allCommit.__next__()
    # logger.info(firstCommit.author_date)
    # projectStartupDate=datetime.strptime(firstCommit.author_date,'%Y-%M-%d')
    # logger.info(projectStartupDate)

    delta = commit.author_date - firstCommit.author_date
    # logger.info(delta.days)
    if delta.days < 7:
        return "OW"
    else:
        if delta.days < 30:
            return "OM"
        else:
            if delta.days < 365:
                return "OY"
            else:
                return "M"


def workloadDistribution(repo, date=None):
    developerWorkload = {}
    if (date != None):

        d1 = datetime(date.year, date.month, 1, 0, 0,0)
        if (date.month == 2):
            d2 = datetime(date.year, date.month, 28)
        else:
            if (date.month == 9 or date.month == 11 or date.month == 4 or date.month == 6):
                d2 = datetime(date.year, date.month, 30)
            else:
                d2 = datetime(date.year, date.month, 31)
        #print(d1)
        #print(d2)

        repo._since=d1
        repo._to=d2

        commit = repo.traverse_commits()


    else:
        commit = repo.traverse_commits()

    for c in commit:


        if c.author.name in developerWorkload:
            developerWorkload[c.author.name] = developerWorkload[c.author.name] + 1

        else:
            developerWorkload[c.author.name] = 1

        # logger.info(developerWorkload[commit.author.name])

    quartili = np.percentile(list(developerWorkload.values()), [25, 75])
    return quartili, developerWorkload


def workloadTag(repo, commit):

    quartili, developerWorkload = workloadDistribution(repo, commit.author_date)

    # logger.info(quartili[0])
    # logger.info(developerWorkload[commit.author.name])
    wl = developerWorkload[commit.author.name]
    if wl < quartili[0]:
        return "L"
    else:
        if wl >= quartili[0] and wl < quartili[1]:
            return "M"
        else:
            if wl >= quartili[1]:
                return "H"


def projectTenureTag(repo, commit):
    quartili, developerWorkload = workloadDistribution(repo)
    pt = developerWorkload[commit.author.name]
    if pt < quartili[0]:
        return "NC"
    else:
        if pt >= quartili[0] and pt < quartili[1]:
            return "M"
        else:
            if pt >= quartili[1]:
                return "E"


def workingOnRelease(commit, releases=None):
    commitDateStr = datetime.strftime(commit.author_date, '%Y-%m-%d')
    commitDate = datetime.strptime(commitDateStr, '%Y-%m-%d')

    result = [x for x in releases if datetime.strptime(x[1], '%Y-%m-%d') > commitDate]
    if result!=None:
        release = min(result, key=lambda x: datetime.strptime(x[1], '%Y-%m-%d') - commitDate)
        releaseDate = datetime.strptime(release[1], '%Y-%m-%d')

        diff = (releaseDate - commitDate).days
    else:
        diff=0

    if diff <= 1:
        return "OD"
    else:
        if diff < 7:
            return "OW"
        else:
            if diff < 30:
                return "OM"
            else:
                return "M"


def survivalAnalysis(repo,row, introducingCommit):
    logger.info("Survival Analysis")
    repo._since = None
    repo._to = None
    firstCommit = min(introducingCommit, key=attrgetter('author_date'))
    repo._single=row[12]
    fixCommit = repo.traverse_commits().__next__()

    numdays = (fixCommit.author_date - firstCommit.author_date).days
    repo._single=None
    repo._from_commit=firstCommit.hash
    repo._to_commit=fixCommit.hash
    commit = repo.traverse_commits()
    numcommit = len(list(commit))
    logger.info("Numero di giorni "+str(numdays))
    logger.info("Numero di commit "+str(numcommit))
    survivalAnalysisFile = open("Risultati/survivalAnalysis.csv", "a", newline='')
    survivalAnalysisWriter = csv.writer(survivalAnalysisFile, delimiter="|")

    survivalAnalysisWriter.writerow([row[0], row[9], numcommit, numdays])
    logger.info(row[0] + "|" + row[9] + "|" + str(numcommit) + "|" + str(numdays))
    survivalAnalysisFile.close()



'''rows = []
for row in df.iterrows():
    rows.append(row)

 logger.info(rows[0][1][0])
sequence = random.sample(rows, 350)

logger.info(len(sequence))
 logger.info(sequence[1])

df1=pd.DataFrame(columns=['CVE','description','repository','fixcommit','fixmodifications'])


for i in range(len(sequence)):
    logger.info("id",sequence[i][0])
    logger.info("repos "+sequence[i][1][11])
    logger.info("hash "+sequence[i][1][12])
    introducing=introducing_commit(sequence[i][1][11],sequence[i][1][12])
    #try:
    for commit in py.RepositoryMining(sequence[i][1][11],single=sequence[i][1][12]).traverse_commits():
                logger.info("fix commit")
                df1.loc[i]=[sequence[i][1][0],sequence[i][1][1],sequence[i][1][11],sequence[i][1][12],commit.modifications]
            #logger.info(df.loc[i][5])
    logger.info("finish fix commit")
    df2=pd.DataFrame()
    for j in range(len(introducing[0])):
                df2['introducingCommit'+str(j)] = introducing[0][j].hash
                df2['introducingCommitModifications'+str(j)] = introducing[1][introducing[0][j].hash]
                logger.info(df2)
    logger.info(df1)
    logger.info(df2)
    except:
        logger.info("Error")

df=pd.concat(df1,df2)
df.to_csv("HowRemove.csv",sep="|")

with open("HowRemove.csv", "w", newline='') as howRemove:
    writer = csv.writer(howRemove, delimiter="|")
    writer.writerow(["CVE", "description", "repository", "fix commit", "introducing commit"])
    for i in range(len(sequence)):
        try:
            introducing = introducing_commit(sequence[i][1][11], sequence[i][1][12])
        except Exception as e:
            logger.info(str(e))
        # commit=py.RepositoryMining(sequence[i][1][11],to_commit=sequence[i][1][12]).traverse_commits()

        if len(introducing[0]) != 0:
            introCommit = []
            for ic in introducing[0]:
                introCommit.append(ic.hash)
            writer.writerow([sequence[i][1][0], sequence[i][1][1], sequence[i][1][11], sequence[i][1][12],
                             ";".join(str(p) for p in introCommit[0])])

for i in (1,350):
    random=random.randint(1,3913)'''

#print(df[0:1])
whyFile = open("Risultati/risWhy.csv", "w", newline='')
writerWhy = csv.writer(whyFile, delimiter="|")
writerWhy.writerow(
        ['CVE', 'Product', 'BF', 'E', 'NF', 'R', 'WR-OD', 'WR-OW', 'WR-OM','WR-M', 'PS-OW', 'PS-OM', 'PS-OY', 'PS-M',
         'W-H', 'W-M', 'W-L', 'PT_E', 'PT_M', 'PT_NC'])
whyFile.close()

survivalAnalysisFile = open("Risultati/survivalAnalysis.csv", "w", newline='')
survivalAnalysisWriter = csv.writer(survivalAnalysisFile, delimiter="|")
survivalAnalysisWriter.writerow(['CVE', 'Product', 'NumCommit', 'NumGiorni'])
survivalAnalysisFile.close()

def getRisultati(start, end):
    for index,row in df[start:end].iterrows():
            logger.info("Riga "+str(index))
            try:
                repo=py.RepositoryMining(row[11])
                introducing = introducing_commit(repo, row[12])



                if len(introducing[0])!=0:

                    #result = when(introducing[0],introducing[1],row[11])
                    repo._single=None
                    '''p = Pool(4)
    
                    vulnerableCases = p.map(why,df.iterrows(),repo,introducing[0],index)'''
                    '''p = Process(target=why, args=(row, repo, introducing[0], index))
                    p.start()
                    p.join()'''
                    thread = threading.Thread(target=why, args=(row, repo, introducing[0]))

                    '''threads = [threading.Thread(target=why, args=(row, repo, introducing[0], index)) for _ in range(4)]
                    [thread.start() for thread in threads]
                    [thread.join() for thread in threads]'''
                    #why(row,repo,introducing[0],index)
                    repo1 = py.RepositoryMining(row[11])
                    thread2 = threading.Thread(target=survivalAnalysis, args=(repo1, row, introducing[0]))
                    thread2.start()
                    thread.start()
                    thread2.join()
                    thread.join()
                    #survivalAnalysis(repo, row, introducing[0],index)
                    '''when = open("Risultati/risWhen.csv", "a", newline='')
                    writerWhen = csv.writer(when, delimiter="|")
                    if index==0:
                        writerWhen.writerow(['CVE', 'Product', 'Min', 'Max', 'Mean', 'Median', 'Variance', ' Standard deviation'])
                    writerWhen.writerow([row[0],row[9],min(result.values()),max(result.values()),mean(result.values()),median(result.values()),pvariance(result.values()),pstdev(result.values())])
                    logger.info(len(result.values()))
                    logger.info("Il minimo numero di commit prima dell'introduzione della vulnerabilita e " + min(result.values()))
                    logger.info("Il massimo del numero di commit prima dell'introduzione della vulnerabilita e " + max(result.values()))
                    logger.info("La media del numero di commit prima dell'introduzione della vulnerabilita e " + mean(result.values()))
                    logger.info("La mediana del numero di commit prima dell'introduzione della vulnerabilita e " + median(result.values()))
                    logger.info("La varianza del numero di commit prima dell'introduzione della vulnerabilita e " + pvariance(result.values()))
                    logger.info("La deviazione standard del numero di commit prima dell'introduzione della vulnerabilita e " + pstdev(result.values()))
                    whyFile = open("Risultati/risWhy.csv", "a", newline='')
                    writerWhy = csv.writer(whyFile, delimiter="|")
                    if index==0:
                        writerWhy.writerow(['CVE', 'Product', 'BF', 'E', 'NF', 'R', 'WR-OD', 'WR-OW', 'WR-OM,WR-M', 'PS-OW', 'PS-OM', 'PS-OY','PS-M', 'W-H', 'W-M', 'W-L', 'PT_E', 'PT_M','PT_NC'])
        
                    writerWhy.writerow([row[0],row[9],tags[0],tags[1],tags[2],tags[3],tags[4],tags[5],tags[6],tags[7],tags[8],tags[9],tags[10],tags[11],tags[12],tags[13],tags[14],tags[15],tags[16],tags[17]])
                    logger.info(row[0] + "|" + row[9] + "|" + str(tags[0]) + "|" + str(tags[1]) + "|" + str(tags[2]) + "|" + str(
                        tags[3]) + "|" + str(tags[4]) + "|" + str(tags[5]) + "|" + str(tags[6]) + "|" + str(tags[7]) + "|" + str(
                        tags[8]) + "|" + str(tags[9]) + "|" + str(tags[10]) + "|" + str(tags[11]) + "|" + str(tags[12]) + "|" + str(
                        tags[13]) + "|" + str(tags[14]) + "|" + str(tags[15]) + "|" + str(tags[16]) + "|" + str(tags[17]))
                    survivalAnalysisFile=open("Risultati/survivalAnalysis.csv","a",newline='')
                    survivalAnalysisWriter = csv.writer(survivalAnalysisFile, delimiter="|")
                    if index==0:
                        survivalAnalysisWriter.writerow(['CVE', 'Product', 'NumCommit', 'NumGiorni'])
        
                    survivalAnalysisWriter.writerow([row[0],row[9],numcommit,numdays])
                    logger.info(row[0] + "|" + row[9] + "|" + str(numcommit) + "|" + str(numdays))'''
                    logger.info("fatto")
            except Exception as e:
                    logger.exception(str(index))
                    #logger.error(str(e))



threads1 = threading.Thread(target=getRisultati,args=(0,743))
threads2 = threading.Thread(target=getRisultati,args=(743,1486))
threads3 = threading.Thread(target=getRisultati,args=(1486,2229))
threads4 = threading.Thread(target=getRisultati,args=(2229,2972))
threads1.start()
threads2.start()
threads3.start()
threads4.start()
threads1.join()
threads2.join()
threads3.join()
threads4.join()


#getRisultati(0,2972)

